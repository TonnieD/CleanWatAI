{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51c81be",
   "metadata": {},
   "source": [
    "# Clean Water AI - Environmental Data Collection\n",
    "\n",
    "This notebook collects environmental data at exact water point locations for spatially and temporally accurate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad52cd2",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae157041",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from scripts.data_extraction import get_wpdx_kenya \n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc360eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "import ee\n",
    "\n",
    "# Authenticate and initialize Earth Engine with Google Cloud credentials and account\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c5be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wpdx = get_wpdx_kenya()\n",
    "\n",
    "\n",
    "# Convert report_date to datetime and create date ranges for environmental data\n",
    "df_wpdx['report_date'] = pd.to_datetime(df_wpdx['report_date'])\n",
    "df_wpdx['env_start_date'] = df_wpdx['report_date'] - timedelta(days=30)\n",
    "df_wpdx['env_end_date'] = df_wpdx['report_date']\n",
    "\n",
    "# Sample subset for processing\n",
    "sample_size = 1000 # min(500, len(kenya_points))\n",
    "kenya_sample = df_wpdx.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Processing {len(kenya_sample)} water points with temporal accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab3f3f2",
   "metadata": {},
   "source": [
    "## Create Earth Engine FeatureCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Earth Engine points from water point coordinates with date info\n",
    "def create_ee_feature(row):\n",
    "    point = ee.Geometry.Point([row['lon_deg'], row['lat_deg']])\n",
    "    return ee.Feature(point, {\n",
    "        'wpdx_id': str(row['wpdx_id']),\n",
    "        'point_id': int(row.name),\n",
    "        'start_date': row['env_start_date'].strftime('%Y-%m-%d'),\n",
    "        'end_date': row['env_end_date'].strftime('%Y-%m-%d')\n",
    "    })\n",
    "\n",
    "water_points_fc = ee.FeatureCollection([create_ee_feature(row) for _, row in kenya_sample.iterrows()])\n",
    "print(\"Water points FeatureCollection created with temporal info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c56d28",
   "metadata": {},
   "source": [
    "## CHIRPS Rainfall Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadd2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample CHIRPS rainfall at water point locations with temporal accuracy\n",
    "def sample_chirps_for_point(feature):\n",
    "    start_date = feature.get('start_date')\n",
    "    end_date = feature.get('end_date')\n",
    "    \n",
    "    chirps_img = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .sum() \\\n",
    "        .rename('rainfall_30d_mm')\n",
    "    \n",
    "    return chirps_img.sampleRegions(\n",
    "        collection=ee.FeatureCollection([feature]),\n",
    "        scale=5000,\n",
    "        geometry=True\n",
    "    ).first().copyProperties(feature)\n",
    "\n",
    "chirps_sampled = water_points_fc.map(sample_chirps_for_point)\n",
    "\n",
    "# Convert to DataFrame\n",
    "chirps_list = chirps_sampled.getInfo()['features']\n",
    "chirps_data = []\n",
    "\n",
    "for feature in chirps_list:\n",
    "    coords = feature['geometry']['coordinates']\n",
    "    props = feature['properties']\n",
    "    chirps_data.append({\n",
    "        'wpdx_id': props.get('wpdx_id'),\n",
    "        'point_id': props.get('point_id'),\n",
    "        'longitude': coords[0],\n",
    "        'latitude': coords[1],\n",
    "        'rainfall_30d_mm': props.get('rainfall_30d_mm'),\n",
    "        'start_date': props.get('start_date'),\n",
    "        'end_date': props.get('end_date')\n",
    "    })\n",
    "\n",
    "df_chirps = pd.DataFrame(chirps_data)\n",
    "df_chirps.to_csv(\"chirps_rainfall_wpdx_points.csv\", index=False)\n",
    "print(f\"CHIRPS data collected: {len(df_chirps)} points with temporal accuracy\")\n",
    "df_chirps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c32052",
   "metadata": {},
   "source": [
    "## MODIS NDVI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078e21c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample MODIS NDVI with all bands at water point locations with temporal accuracy\n",
    "def sample_ndvi_for_point(feature):\n",
    "    start_date = feature.get('start_date')\n",
    "    end_date = feature.get('end_date')\n",
    "    \n",
    "    ndvi_collection = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .select(['DayOfYear', 'DetailedQA', 'EVI', 'NDVI', 'RelativeAzimuth', \n",
    "                 'SolarZenith', 'SummaryQA', 'ViewZenith', 'sur_refl_b01', \n",
    "                 'sur_refl_b02', 'sur_refl_b03', 'sur_refl_b07']) \\\n",
    "        .mean()\n",
    "\n",
    "    # Apply proper scaling factors\n",
    "    ndvi_scaled = ndvi_collection.select(['NDVI', 'EVI']).multiply(0.0001) \\\n",
    "        .addBands(ndvi_collection.select(['sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03', 'sur_refl_b07']).multiply(0.0001)) \\\n",
    "        .addBands(ndvi_collection.select(['RelativeAzimuth', 'SolarZenith', 'ViewZenith']).multiply(0.01)) \\\n",
    "        .addBands(ndvi_collection.select(['DayOfYear', 'DetailedQA', 'SummaryQA']))\n",
    "\n",
    "    return ndvi_scaled.sampleRegions(\n",
    "        collection=ee.FeatureCollection([feature]),\n",
    "        scale=250,\n",
    "        geometry=True\n",
    "    ).first().copyProperties(feature)\n",
    "\n",
    "ndvi_sampled = water_points_fc.map(sample_ndvi_for_point)\n",
    "\n",
    "# Convert to DataFrame\n",
    "ndvi_list = ndvi_sampled.getInfo()['features']\n",
    "ndvi_data = []\n",
    "\n",
    "for feature in ndvi_list:\n",
    "    coords = feature['geometry']['coordinates']\n",
    "    props = feature['properties']\n",
    "    ndvi_data.append({\n",
    "        'wpdx_id': props.get('wpdx_id'),\n",
    "        'point_id': props.get('point_id'),\n",
    "        'longitude': coords[0],\n",
    "        'latitude': coords[1],\n",
    "        'DayOfYear': props.get('DayOfYear'),\n",
    "        'DetailedQA': props.get('DetailedQA'),\n",
    "        'EVI': props.get('EVI'),\n",
    "        'NDVI': props.get('NDVI'),\n",
    "        'RelativeAzimuth': props.get('RelativeAzimuth'),\n",
    "        'SolarZenith': props.get('SolarZenith'),\n",
    "        'SummaryQA': props.get('SummaryQA'),\n",
    "        'ViewZenith': props.get('ViewZenith'),\n",
    "        'sur_refl_b01': props.get('sur_refl_b01'),\n",
    "        'sur_refl_b02': props.get('sur_refl_b02'),\n",
    "        'sur_refl_b03': props.get('sur_refl_b03'),\n",
    "        'sur_refl_b07': props.get('sur_refl_b07'),\n",
    "    'start_date': props.get('start_date'),\n",
    "    'end_date': props.get('end_date')\n",
    "})\n",
    "\n",
    "df_ndvi = pd.DataFrame(ndvi_data)\n",
    "df_ndvi.to_csv(\"modis_ndvi_all_bands_wpdx_points.csv\", index=False)\n",
    "print(f\"MODIS data collected: {len(df_ndvi)} points with all bands and temporal accuracy\")\n",
    "df_ndvi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8395190",
   "metadata": {},
   "source": [
    "## MODIS LST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ac889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample MODIS LST at water point locations with temporal accuracy\n",
    "def sample_lst_for_point(feature):\n",
    "    start_date = feature.get('start_date')\n",
    "    end_date = feature.get('end_date')\n",
    "    \n",
    "    lst_img = ee.ImageCollection(\"MODIS/061/MOD11A2\") \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .select('LST_Day_1km') \\\n",
    "        .mean() \\\n",
    "        .multiply(0.02) \\\n",
    "        .subtract(273.15) \\\n",
    "        .rename('lst_celsius')\n",
    "\n",
    "    return lst_img.sampleRegions(\n",
    "        collection=ee.FeatureCollection([feature]),\n",
    "        scale=1000,\n",
    "        geometry=True\n",
    "    ).first().copyProperties(feature)\n",
    "\n",
    "lst_sampled = water_points_fc.map(sample_lst_for_point)\n",
    "\n",
    "# Convert to DataFrame\n",
    "lst_list = lst_sampled.getInfo()['features']\n",
    "lst_data = []\n",
    "\n",
    "for feature in lst_list:\n",
    "    coords = feature['geometry']['coordinates']\n",
    "    props = feature['properties']\n",
    "    lst_data.append({\n",
    "        'wpdx_id': props.get('wpdx_id'),\n",
    "        'point_id': props.get('point_id'),\n",
    "        'longitude': coords[0],\n",
    "        'latitude': coords[1],\n",
    "        'lst_celsius': props.get('lst_celsius'),\n",
    "        'start_date': props.get('start_date'),\n",
    "        'end_date': props.get('end_date')\n",
    "    })\n",
    "\n",
    "df_lst = pd.DataFrame(lst_data)\n",
    "df_lst.to_csv(\"modis_lst_wpdx_points.csv\", index=False)\n",
    "print(f\"LST data collected: {len(df_lst)} points with temporal accuracy\")\n",
    "df_lst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace5c2a",
   "metadata": {},
   "source": [
    "## SMAP Soil Moisture Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69120ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample SMAP soil moisture at water point locations with temporal accuracy\n",
    "def sample_smap_for_point(feature):\n",
    "    start_date = feature.get('start_date')\n",
    "    end_date = feature.get('end_date')\n",
    "    \n",
    "    smap_img = ee.ImageCollection(\"NASA/SMAP/SPL3SMP_E/006\") \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .select(['soil_moisture_am', 'soil_moisture_pm']) \\\n",
    "        .mean()\n",
    "\n",
    "    return smap_img.sampleRegions(\n",
    "        collection=ee.FeatureCollection([feature]),\n",
    "        scale=9000,\n",
    "        geometry=True\n",
    "    ).first().copyProperties(feature)\n",
    "\n",
    "smap_sampled = water_points_fc.map(sample_smap_for_point)\n",
    "\n",
    "# Convert to DataFrame\n",
    "smap_list = smap_sampled.getInfo()['features']\n",
    "smap_data = []\n",
    "\n",
    "for feature in smap_list:\n",
    "    coords = feature['geometry']['coordinates']\n",
    "    props = feature['properties']\n",
    "    smap_data.append({\n",
    "        'wpdx_id': props.get('wpdx_id'),\n",
    "        'point_id': props.get('point_id'),\n",
    "        'longitude': coords[0],\n",
    "        'latitude': coords[1],\n",
    "        'soil_moisture_am': props.get('soil_moisture_am'),\n",
    "        'soil_moisture_pm': props.get('soil_moisture_pm'),\n",
    "        'start_date': props.get('start_date'),\n",
    "        'end_date': props.get('end_date')\n",
    "    })\n",
    "\n",
    "df_smap = pd.DataFrame(smap_data)\n",
    "df_smap.to_csv(\"smap_soil_moisture_wpdx_points.csv\", index=False)\n",
    "print(f\"SMAP data collected: {len(df_smap)} points with temporal accuracy\")\n",
    "df_smap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ee9d0",
   "metadata": {},
   "source": [
    "## WorldPop Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c707200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample WorldPop population density (using 2020 as baseline since it's demographic data)\n",
    "worldpop_img = ee.ImageCollection(\"WorldPop/GP/100m/pop\") \\\n",
    "    .filterDate('2020-01-01', '2020-12-31') \\\n",
    "    .mosaic() \\\n",
    "    .rename('pop_density')\n",
    "\n",
    "worldpop_sampled = worldpop_img.sampleRegions(\n",
    "    collection=water_points_fc,\n",
    "    scale=100,\n",
    "    geometries=True\n",
    ")\n",
    "\n",
    "# Convert to DataFrame\n",
    "worldpop_list = worldpop_sampled.getInfo()['features']\n",
    "worldpop_data = []\n",
    "\n",
    "for feature in worldpop_list:\n",
    "    coords = feature['geometry']['coordinates']\n",
    "    props = feature['properties']\n",
    "    worldpop_data.append({\n",
    "        'wpdx_id': props.get('wpdx_id'),\n",
    "        'point_id': props.get('point_id'),\n",
    "        'longitude': coords[0],\n",
    "        'latitude': coords[1],\n",
    "        'pop_density': props.get('pop_density')\n",
    "    })\n",
    "\n",
    "df_worldpop = pd.DataFrame(worldpop_data)\n",
    "df_worldpop.to_csv(\"worldpop_wpdx_points.csv\", index=False)\n",
    "print(f\"WorldPop data collected: {len(df_worldpop)} points\")\n",
    "df_worldpop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a8f63",
   "metadata": {},
   "source": [
    "## Merge All Environmental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e626095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all environmental datasets with water point data\n",
    "df_merged = df_chirps[['wpdx_id', 'point_id', 'longitude', 'latitude', 'rainfall_30d_mm']] \\\n",
    "    .merge(df_ndvi[['point_id', 'DayOfYear', 'DetailedQA', 'EVI', 'NDVI', 'RelativeAzimuth', \n",
    "                    'SolarZenith', 'SummaryQA', 'ViewZenith', 'sur_refl_b01', 'sur_refl_b02', \n",
    "                    'sur_refl_b03', 'sur_refl_b07']], on='point_id', how='left') \\\n",
    "    .merge(df_lst[['point_id', 'lst_celsius']], on='point_id', how='left') \\\n",
    "    .merge(df_smap[['point_id', 'soil_moisture_am', 'soil_moisture_pm']], on='point_id', how='left') \\\n",
    "    .merge(df_worldpop[['point_id', 'pop_density']], on='point_id', how='left')\n",
    "\n",
    "# Add original water point data with temporal information\n",
    "df_final = kenya_sample[['wpdx_id', 'lat_deg', 'lon_deg', 'report_date', 'status_clean', \n",
    "                        'water_source_clean', 'water_tech_clean', 'management_clean']] \\\n",
    "    .merge(df_merged, left_on='wpdx_id', right_on='wpdx_id', how='inner')\n",
    "\n",
    "df_final.to_csv(\"final_wpdx_environmental_data.csv\", index=False)\n",
    "print(f\"Final merged dataset: {len(df_final)} points with {len(df_final.columns)} features\")\n",
    "print(f\"Temporal range: {df_final['report_date'].min()} to {df_final['report_date'].max()}\")\n",
    "print(f\"Missing values:\\n{df_final.isnull().sum()}\")\n",
    "df_final.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
